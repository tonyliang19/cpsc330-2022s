import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

plt.rcParams["font.size"] = 16

from sklearn.model_selection import cross_val_score, cross_validate, train_test_split
from sklearn.tree import DecisionTreeClassifier


spotify_df = pd.read_csv("spotify.csv", index_col = 0)
spotify_df.head()



df_train, df_test = train_test_split(spotify_df, test_size=0.25, random_state=123)
print("Training examples: ", df_train.shape[0])
print("Testing examples: ", df_test.shape[0])


c = df_train.describe().iloc[[3, 7]]
c


negative_examples = df_train.query("target == 0")
positive_examples = df_train.query("target == 1")


# you could add "loudness" to test and compare to fig provided
for col in ["danceability", "tempo", "energy", "valence"]:
    plt.hist(positive_examples[[col]], bins=50, color="orange",
             label="1 (Positive)", alpha = 0.4)
    plt.hist(negative_examples[[col]], bins=50, color="c",
             label="0 (Negative)")
    plt.xlabel(col)
    plt.ylabel("count")
    plt.title("Histogram of " + col + " by target class")
    plt.legend()
    plt.show()
    


df_train[["song_title", "artist"]].head()


X_train, y_train = df_train.drop(columns=["target", "song_title", "artist"]), df_train["target"]
X_test, y_test = df_test.drop(columns=["target", "song_title", "artist"]), df_test["target"]


model = DecisionTreeClassifier()  # check max depth
model.fit(X_train, y_train)  # Fit a decision tree
print("Train accuracy:  %0.3f" % model.score(X_train, y_train))
print("Test accuracy:   %0.3f" % model.score(X_test, y_test))


first_ex = X_train.iloc[[0]]
model.predict(first_ex)


model = DecisionTreeClassifier(max_depth=None)  # Change a max_depth
cv_scores = cross_val_score(model, X_train, y_train, cv=10)
print(cv_scores)
print(f"Average cross-validation score = {np.mean(cv_scores):.2f}")
print(f"Standard deviation of cross-validation score = {np.std(cv_scores):.2f}")


# Validation Score == Test_Score in cross_validate


scores = cross_validate(model, X_train, y_train, cv=10, return_train_score=True)
sco = pd.DataFrame(scores)
cvs = pd.DataFrame(cv_scores) # from 2c
mean_test_score = sco["test_score"].mean()
mean_train_score = sco["train_score"].mean()
print("mean test score:",mean_test_score)
print("mean train score:",mean_train_score)
sco



#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
# Adapted from Lecture 3
results_dict = {
    "depth": [],
    "train_score":[],
    "cross_validation_score": [],
}
param_grid = {"max_depth": np.arange(1, 26)}

for depth in param_grid["max_depth"]:
    model = DecisionTreeClassifier(max_depth=depth)
    scores = cross_validate(model, X_train, y_train, cv=10, return_train_score=True)
    results_dict["depth"].append(depth)
    results_dict["cross_validation_score"].append(np.mean(scores["test_score"]))
    results_dict["train_score"].append(np.mean(scores["train_score"]))

results_df = pd.DataFrame(results_dict)
results_df = results_df.set_index("depth")
results_df[["train_score", "cross_validation_score"]].plot(ylabel = "score", title = "Relationship among train and cross validate score with depth");
best_depth_error = np.max(results_df["cross_validation_score"])
best_depth_index = np.argmax(results_df["cross_validation_score"])
best_depth = results_df.index.values[best_depth_index] # max_depth = 4


model = DecisionTreeClassifier(max_depth=best_depth)
model.fit(X_train,y_train)
print("Test score is : ", model.score(X_test, y_test))

